{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP3MpQN93+zkSVxTV6y5Zlq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrorostagno/tesis/blob/main/Tesis_nuevo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usar A100, es el que mejor resultados me dio hasta ahora"
      ],
      "metadata": {
        "id": "Qavi6v5_xrjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5djEVQr1xWU6",
        "outputId": "2f984f44-772b-41a5-efd0-5e0b871bc805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "dataset_path = '/content/drive/Othercomputers/My Mac/Data/train'\n",
        "\n",
        "# 🗂️ Carpetas base en Drive\n",
        "BASE_DIR = \"/content/drive/MyDrive/Tesis UTDT\"\n",
        "CACHE_DIR = os.path.join(BASE_DIR, \"cache\")\n",
        "EXPERIMENTS_DIR = os.path.join(BASE_DIR, \"experimentos\")\n",
        "\n",
        "# ⏱️ Nombre único del experimento basado en fecha y hora\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "RUN_DIR = os.path.join(EXPERIMENTS_DIR, timestamp)\n",
        "\n",
        "# 📁 Crear carpetas si no existen\n",
        "os.makedirs(CACHE_DIR, exist_ok=True)\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"📁 Cachés en:     {CACHE_DIR}\")\n",
        "print(f\"📁 Resultados en: {RUN_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLXmQkaSxz8D",
        "outputId": "d42f2190-82ec-4b9c-c93d-a50d4fff51a7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Cachés en:     /content/drive/MyDrive/Tesis UTDT/cache\n",
            "📁 Resultados en: /content/drive/MyDrive/Tesis UTDT/experimentos/20250622-221825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 📦 Clase personalizada para cargar el dataset CelebA-Spoof (u otro similar estructurado por carpetas)\n",
        "\n",
        "# class CelebASpoofDataset(Dataset):\n",
        "#     def __init__(self, root_dir, transform=None, cache_file=None, max_samples=None):\n",
        "#         \"\"\"\n",
        "#         Inicializa el dataset.\n",
        "\n",
        "#         Parámetros:\n",
        "#         - root_dir (str): Ruta raíz del dataset con estructura jerárquica (sujetos > spoof/live > imágenes).\n",
        "#         - transform (callable, opcional): Transformaciones a aplicar a cada imagen.\n",
        "#         - cache_file (str, opcional): Ruta para guardar o cargar el cache de rutas e índices.\n",
        "#         - max_samples (int, opcional): Límite máximo de muestras a cargar (útil para pruebas rápidas).\n",
        "#         \"\"\"\n",
        "#         self.root_dir = root_dir\n",
        "#         self.transform = transform\n",
        "#         self.image_paths = []\n",
        "#         self.labels = []\n",
        "\n",
        "#         if cache_file is not None and os.path.exists(cache_file):\n",
        "#             print(\"Cargando dataset desde cache...\")\n",
        "#             with open(cache_file, 'rb') as f:\n",
        "#                 self.image_paths, self.labels = pickle.load(f)\n",
        "#         else:\n",
        "#             print(\"Generando la lista de imágenes usando os.scandir...\")\n",
        "#             # Variable para determinar si ya se alcanzó el máximo de muestras\n",
        "#             max_reached = False\n",
        "#             with os.scandir(root_dir) as subjects:\n",
        "#                 for subject in subjects:\n",
        "#                     if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "#                         max_reached = True\n",
        "#                         break\n",
        "#                     if subject.is_dir():\n",
        "#                         subject_path = subject.path\n",
        "#                         with os.scandir(subject_path) as type_entries:\n",
        "#                             for entry in type_entries:\n",
        "#                                 if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "#                                     max_reached = True\n",
        "#                                     break\n",
        "#                                 if entry.is_dir():\n",
        "#                                     image_type = entry.name  # 'live' o 'spoof'\n",
        "#                                     with os.scandir(entry.path) as files:\n",
        "#                                         for file_entry in files:\n",
        "#                                             if file_entry.is_file() and file_entry.name.lower().endswith(('.jpg', '.png')):\n",
        "#                                                 self.image_paths.append(file_entry.path)\n",
        "#                                                 self.labels.append(0 if image_type == 'spoof' else 1)\n",
        "#                                                 if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "#                                                     max_reached = True\n",
        "#                                                     break\n",
        "#                                         if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "#                                             break\n",
        "#                             if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "#                                 break\n",
        "#                     if max_reached:\n",
        "#                         break\n",
        "#             # Guardar en cache si se especifica\n",
        "#             if cache_file is not None:\n",
        "#                 with open(cache_file, 'wb') as f:\n",
        "#                     pickle.dump((self.image_paths, self.labels), f)\n",
        "#                 print(\"Cache guardado en\", cache_file)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         \"\"\"Devuelve la cantidad total de muestras en el dataset.\"\"\"\n",
        "#         return len(self.image_paths)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         \"\"\"\n",
        "#         Devuelve una imagen y su etiqueta correspondiente.\n",
        "\n",
        "#         - Abre la imagen en formato RGB.\n",
        "#         - Aplica transformaciones si fueron especificadas.\n",
        "#         - Devuelve un tensor y un entero (0=spoof, 1=live).\n",
        "#         \"\"\"\n",
        "#         image_path = self.image_paths[idx]\n",
        "#         image = Image.open(image_path).convert('RGB')\n",
        "#         label = self.labels[idx]\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "#         return image, label\n",
        "\n",
        "class CelebASpoofDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, cache_file=None, max_samples=None, balance=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        if cache_file is not None and os.path.exists(cache_file):\n",
        "            print(\"Cargando dataset desde cache...\")\n",
        "            with open(cache_file, 'rb') as f:\n",
        "                self.image_paths, self.labels = pickle.load(f)\n",
        "        else:\n",
        "            print(\"Generando la lista de imágenes usando os.scandir...\")\n",
        "            max_reached = False\n",
        "            with os.scandir(root_dir) as subjects:\n",
        "                for subject in subjects:\n",
        "                    if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "                        max_reached = True\n",
        "                        break\n",
        "                    if subject.is_dir():\n",
        "                        subject_path = subject.path\n",
        "                        with os.scandir(subject_path) as type_entries:\n",
        "                            for entry in type_entries:\n",
        "                                if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "                                    max_reached = True\n",
        "                                    break\n",
        "                                if entry.is_dir():\n",
        "                                    image_type = entry.name\n",
        "                                    with os.scandir(entry.path) as files:\n",
        "                                        for file_entry in files:\n",
        "                                            if file_entry.is_file() and file_entry.name.lower().endswith(('.jpg', '.png')):\n",
        "                                                self.image_paths.append(file_entry.path)\n",
        "                                                self.labels.append(0 if image_type == 'spoof' else 1)\n",
        "                                                if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "                                                    max_reached = True\n",
        "                                                    break\n",
        "                                        if max_reached:\n",
        "                                            break\n",
        "                            if max_reached:\n",
        "                                break\n",
        "                    if max_reached:\n",
        "                        break\n",
        "            if cache_file is not None:\n",
        "                with open(cache_file, 'wb') as f:\n",
        "                    pickle.dump((self.image_paths, self.labels), f)\n",
        "                print(\"Cache guardado en\", cache_file)\n",
        "\n",
        "        # ⚖️ Balanceo posterior (solo si balance=True)\n",
        "        if balance:\n",
        "            print(\"⚖️ Aplicando balance de clases...\")\n",
        "            spoof_samples = [(p, l) for p, l in zip(self.image_paths, self.labels) if l == 0]\n",
        "            live_samples  = [(p, l) for p, l in zip(self.image_paths, self.labels) if l == 1]\n",
        "            min_len = min(len(spoof_samples), len(live_samples))\n",
        "\n",
        "            # Cortamos la clase mayoritaria\n",
        "            spoof_samples = spoof_samples[:min_len]\n",
        "            live_samples = live_samples[:min_len]\n",
        "\n",
        "            combined = spoof_samples + live_samples\n",
        "            random.shuffle(combined)\n",
        "            self.image_paths, self.labels = zip(*combined)\n",
        "            self.image_paths = list(self.image_paths)\n",
        "            self.labels = list(self.labels)\n",
        "\n",
        "            print(f\"📊 Dataset balanceado: {min_len} spoof + {min_len} live = {2 * min_len} total\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GRN9PQq_0EoH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 📁 Definición de rutas a cada partición del dataset (entrenamiento, validación y test)\n",
        "train_data_dir = '/content/drive/Othercomputers/My Mac/Data/train/train'\n",
        "val_data_dir   = '/content/drive/Othercomputers/My Mac/Data/train/val'\n",
        "test_data_dir  = '/content/drive/Othercomputers/My Mac/Data/train/test'\n",
        "\n",
        "# 📐 Dimensiones estándar a las que se redimensionarán todas las imágenes\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "# ⚙️ Tamaño del batch para los DataLoaders\n",
        "batch_size = 128\n",
        "\n",
        "# 🌀 Transformaciones de preprocesamiento para cada conjunto de datos\n",
        "data_transforms = {\n",
        "    # 'train': transforms.Compose([\n",
        "    #     transforms.Resize((img_width, img_height)),              # Redimensiona la imagen a 224x224\n",
        "    #     transforms.RandomHorizontalFlip(),                       # Aplica flip horizontal aleatorio (augmentación)\n",
        "    #     transforms.ToTensor(),                                   # Convierte PIL Image a tensor\n",
        "    #     transforms.Normalize([0.485, 0.456, 0.406],              # Normalización con media y desvío estándar de ImageNet\n",
        "    #                          [0.229, 0.224, 0.225])\n",
        "    # ]),\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((img_width + 32, img_height + 32)),    # Aumenta resolución previa a crop\n",
        "        transforms.RandomResizedCrop((img_width, img_height), scale=(0.8, 1.0)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.02),\n",
        "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),\n",
        "        transforms.RandomApply([transforms.RandomRotation(10)], p=0.3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((img_width, img_height)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((img_width, img_height)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ],
      "metadata": {
        "id": "9q5n9D1s01lK"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "\n",
        "¿Por qué se redimensiona a (224, 224)?\n",
        "\n",
        "Motivo principal: muchos modelos preentrenados (como MobileNetV2, ResNet, VGG) fueron entrenados originalmente con imágenes de 224x224 píxeles.\n",
        "Usar ese tamaño:\n",
        "Permite reutilizar pesos preentrenados (transfer learning) sin modificar la arquitectura.\n",
        "Asegura una entrada consistente para la red (todas las imágenes con el mismo tamaño).\n",
        "Además, 224×224 es un buen balance entre:\n",
        "Calidad visual suficiente para tareas de clasificación.\n",
        "Eficiencia computacional (no tan pesado como 512x512, por ejemplo).\n",
        "\n",
        "\n",
        "\n",
        "¿Qué significa batch_size = 32 y por qué ese número?\n",
        "\n",
        "El batch size es la cantidad de imágenes que se procesan simultáneamente en una pasada (forward + backward) durante el entrenamiento.\n",
        "Tamaño común: 8, 16, 32, 64, etc.\n",
        "Usar 32 implica:\n",
        "Buena estabilidad numérica del gradiente.\n",
        "Razonable uso de memoria en GPU (ni muy chico ni muy grande).\n",
        "En general:\n",
        "Batches chicos (8-16): más precisos pero lentos.\n",
        "Batches grandes (64-128+): más rápidos pero requieren más memoria y pueden converger peor.\n",
        "Batch = 32 es una elección segura, ampliamente utilizada, y probablemente compatible con el uso de GPU en Colab.\n",
        "\n",
        "\n",
        "\n",
        "Normalizacion\n",
        "\n",
        "Se utiliza la normalización estándar de ImageNet (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) porque el modelo base empleado fue preentrenado sobre este dataset. Esta normalización asegura que las imágenes de entrada tengan una distribución similar a la vista durante el preentrenamiento, lo cual es esencial para transfer learning efectivo.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "5TU6nbZZ1HhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad máxima de muestras por partición (ajustable)\n",
        "train_max_samples = 50000\n",
        "val_max_samples = 10000\n",
        "test_max_samples = 5000\n",
        "\n",
        "# 📦 Dataset de entrenamiento con cache y transformación\n",
        "train_dataset = CelebASpoofDataset(\n",
        "    root_dir=train_data_dir,\n",
        "    transform=data_transforms['train'],\n",
        "    cache_file=os.path.join(CACHE_DIR, \"train_dataset_cache_1.pkl\"),\n",
        "    max_samples=train_max_samples,\n",
        "    balance=True\n",
        "    # max_subjects=300\n",
        ")\n",
        "\n",
        "# 📦 Dataset de validación\n",
        "val_dataset = CelebASpoofDataset(\n",
        "    root_dir=val_data_dir,\n",
        "    transform=data_transforms['val'],\n",
        "    cache_file=os.path.join(CACHE_DIR, \"val_dataset_cache_1.pkl\"),\n",
        "    max_samples=val_max_samples,\n",
        "    # balance=True\n",
        "    # max_subjects=300\n",
        ")\n",
        "\n",
        "# 📦 Dataset de test\n",
        "# test_dataset = CelebASpoofDataset(\n",
        "#     root_dir=test_data_dir,\n",
        "#     transform=data_transforms['test'],\n",
        "#     cache_file=os.path.join(CACHE_DIR, \"test_dataset_cache.pkl\"),\n",
        "#     max_samples=test_max_samples\n",
        "#     # max_subjects=300\n",
        "# )\n",
        "\n",
        "# 🔄 DataLoaders para alimentar los datos al modelo en mini-batches\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,     # Cantidad de muestras por batch (definido previamente como 32)\n",
        "    shuffle=True,              # Mezcla los datos en cada época (importante para entrenamiento)\n",
        "    num_workers=8,             # Procesos paralelos para cargar datos (ajustar según GPU/Colab)\n",
        "    pin_memory=True            # Optimiza transferencia a GPU (si se usa CUDA)\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,             # No se mezcla para evaluación consistente\n",
        "    num_workers=8,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# test_loader = DataLoader(\n",
        "#     test_dataset,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=False,\n",
        "#     num_workers=8,\n",
        "#     pin_memory=True\n",
        "# )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhXgn2Pn5wKp",
        "outputId": "ebcc7f5c-34a6-4227-b767-7ec18442f796"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando dataset desde cache...\n",
            "⚖️ Aplicando balance de clases...\n",
            "📊 Dataset balanceado: 17123 spoof + 17123 live = 34246 total\n",
            "Generando la lista de imágenes usando os.scandir...\n",
            "Cache guardado en /content/drive/MyDrive/Tesis UTDT/cache/val_dataset_cache_1.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# 🧠 Carga de modelo preentrenado\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "\n",
        "# 🔧 Modificación de la última capa para clasificación binaria\n",
        "# Extraemos el número de entradas de la capa final\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "\n",
        "# Reemplazamos la última capa por una nueva totalmente conectada con 2 salidas (spoof / live)\n",
        "model.classifier[1] = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "# ⚙️ Optimizador\n",
        "# Adam es un optimizador eficiente y ampliamente utilizado\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005) #Cambie el learning rate de 0.001 a 0.0005\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPA07Eq43g4p",
        "outputId": "6b046cb1-bbfc-4909-adcf-bb83a4403f0d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "MobileNetV2\n",
        "Ventajas principales:\n",
        "Modelo ligero y eficiente: MobileNetV2 está diseñado para ser rápido y liviano, ideal si usás Colab, entornos con GPU limitada o pensás implementarlo en dispositivos móviles o edge.\n",
        "Alto rendimiento: A pesar de ser liviano, alcanza buena precisión en tareas de clasificación.\n",
        "Transfer learning efectivo: Funciona muy bien con fine-tuning para tareas con pocos datos (como en muchos proyectos de tesis).\n",
        "✅ Justificación para tu tesis:\n",
        "MobileNetV2 se eligió por su eficiencia computacional y alto rendimiento en clasificación de imágenes, siendo especialmente útil en contextos con recursos limitados o para aplicaciones en tiempo real. Además, su arquitectura permite realizar transfer learning de forma efectiva.\n",
        "\n",
        "\n",
        "\n",
        "📥 ¿Por qué pretrained=True?\n",
        "Significado:\n",
        "Carga pesos ya entrenados en el dataset ImageNet (más de 1M de imágenes en 1000 clases).\n",
        "Esto significa que las primeras capas del modelo ya están optimizadas para detectar características visuales genéricas como bordes, texturas, patrones, etc.\n",
        "Ventajas:\n",
        "Mejora la convergencia (entrena más rápido).\n",
        "Mejora la precisión, especialmente si tenés poco volumen de datos.\n",
        "Es la base del Transfer Learning.\n",
        "Justificación para tu tesis:\n",
        "Se utilizan pesos preentrenados sobre ImageNet para aprovechar características visuales genéricas aprendidas previamente, acelerando el entrenamiento y mejorando el rendimiento con un volumen de datos moderado.\n",
        "\n",
        "\n",
        "¿Por qué CrossEntropyLoss?\n",
        "¿Qué hace?\n",
        "Es la función de pérdida estándar para clasificación multi-clase (incluye binaria).\n",
        "Combina LogSoftmax + Negative Log Likelihood, calculando la discrepancia entre las probabilidades predichas y la clase verdadera.\n",
        "Justificación:\n",
        "Es adecuada cuando las etiquetas están codificadas como enteros (0 o 1).\n",
        "Automáticamente maneja logits (sin necesidad de aplicar softmax manual).\n",
        "Justificación para tu tesis:\n",
        "Se utiliza la función de pérdida CrossEntropyLoss, ampliamente aceptada para problemas de clasificación, ya que penaliza las predicciones incorrectas proporcionalmente a su confianza, incentivando al modelo a asignar probabilidades más altas a las clases correctas.\n",
        "\n",
        "\n",
        "\n",
        "⚙️ ¿Por qué Adam y lr=0.001?\n",
        "\n",
        "¿Qué es Adam?\n",
        "Un optimizador adaptativo que ajusta la tasa de aprendizaje individualmente para cada peso.\n",
        "Combina ventajas de:\n",
        "RMSProp (ajuste por histórico de gradientes)\n",
        "Momentum (aceleración del aprendizaje)\n",
        "¿Por qué lr = 0.001?\n",
        "Es el valor por defecto y recomendado para Adam.\n",
        "Proporciona un balance entre estabilidad y velocidad en la mayoría de los casos.\n",
        "Si lo aumentás (por ej. 0.01):\n",
        "El modelo puede aprender más rápido pero también volverse inestable.\n",
        "Si lo bajás (por ej. 0.0001):\n",
        "El modelo aprende más lento, pero más establemente (útil si tenés overfitting o datos ruidosos).\n",
        "Justificación para tu tesis:\n",
        "Se utiliza el optimizador Adam por su capacidad adaptativa y eficiencia, permitiendo un entrenamiento más rápido y estable sin necesidad de ajustes manuales constantes. La tasa de aprendizaje inicial (lr = 0.001) es un valor estándar que ofrece un equilibrio entre velocidad de convergencia y estabilidad numérica.\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "4F6zkDIs4CZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ⚙️ Detectar el dispositivo: GPU si está disponible, si no usa CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 🧠 Mover el modelo al dispositivo seleccionado\n",
        "model = model.to(device)\n",
        "\n",
        "# 📊 Calcular la distribución de clases en el dataset de entrenamiento\n",
        "labels = np.array(train_dataset.labels)\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "print(f\"Distribución de clases en entrenamiento: {dict(zip(unique, counts))}\")\n",
        "\n",
        "# 🧮 Calcular pesos inversamente proporcionales a la cantidad de muestras por clase\n",
        "total = counts.sum()\n",
        "weights = [total / c for c in counts]  # Más peso a la clase menos representada\n",
        "\n",
        "# Convertir a tensor y mover a GPU (si está disponible)\n",
        "weights_tensor = torch.FloatTensor(weights).to(device)\n",
        "print(\"Pesos de clases:\", weights_tensor)\n",
        "\n",
        "# 🎯 Definir una función de pérdida ponderada para tratar el desbalance de clases\n",
        "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJdVqM864oJ0",
        "outputId": "019a68ca-8d6a-498b-a900-6ff8260bfb48"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución de clases en entrenamiento: {np.int64(0): np.int64(17123), np.int64(1): np.int64(17123)}\n",
            "Pesos de clases: tensor([2., 2.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "El dataset de entrenamiento puede estar desbalanceado, es decir, tener más ejemplos de una clase que de otra. Para evitar que el modelo aprenda a favorecer la clase mayoritaria, se calcula la distribución real de clases y se asignan pesos inversamente proporcionales a su frecuencia. Estos pesos se utilizan en la función CrossEntropyLoss para penalizar más fuertemente los errores en las clases menos representadas. Esto mejora la equidad del modelo y su capacidad de detectar ambas clases por igual.\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
        "Con pesos según distribución\n",
        "Aplica mayor penalización a la clase minoritaria.\n",
        "Específicamente útil si tu problema tiene desbalance de clases.\n",
        "Mejora métricas como recall, F1-score macro y balanced accuracy.\n",
        "</details>"
      ],
      "metadata": {
        "id": "ZSlqAyV56O_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import sklearn.metrics as metrics\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# 🔁 Función para entrenar una sola época usando Mixed Precision\n",
        "def train_epoch(model, train_loader, optimizer, criterion, device, scaler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ⚙️ Entrenamiento en precisión mixta (float16 + float32)\n",
        "        with autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        total_samples += inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = running_corrects.double() / total_samples\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# 📊 Función para evaluar el modelo en validación y obtener métricas\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_corrects = 0\n",
        "    total_samples = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = val_loss / total_samples\n",
        "    epoch_acc = val_corrects.double() / total_samples\n",
        "    report = metrics.classification_report(all_labels, all_preds, output_dict=True, zero_division=0)\n",
        "\n",
        "    return epoch_loss, epoch_acc, report, all_preds, all_labels\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# 🚀 Función principal de entrenamiento con validación, checkpoints, early stopping y logging\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device,\n",
        "                num_epochs=10, patience=3, checkpoint_interval=1, log_dir=None):\n",
        "\n",
        "    if log_dir is None:\n",
        "        log_dir = os.path.join(RUN_DIR, \"tensorboard\")\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "    # 📝 Guardar configuración\n",
        "    config = {\n",
        "        \"num_epochs\": num_epochs,\n",
        "        \"patience\": patience,\n",
        "        \"checkpoint_interval\": checkpoint_interval,\n",
        "        \"batch_size\": train_loader.batch_size,\n",
        "        \"optimizer\": type(optimizer).__name__,\n",
        "        \"learning_rate\": optimizer.param_groups[0][\"lr\"],\n",
        "    }\n",
        "    with open(os.path.join(RUN_DIR, \"config.json\"), \"w\") as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "    scaler = GradScaler()\n",
        "    best_val_loss = float('inf')\n",
        "    trigger_times = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}\\n' + '-' * 10)\n",
        "\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device, scaler)\n",
        "        val_loss, val_acc, report, all_preds, all_labels = validate_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        # para modificar el learning rate dinamicamente\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Mostrar el LR actual\n",
        "        for i, param_group in enumerate(optimizer.param_groups):\n",
        "            print(f\"🔁 Learning Rate actual: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f}  Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss:   {val_loss:.4f}  Acc: {val_acc:.4f}')\n",
        "        print(metrics.classification_report(all_labels, all_preds, target_names=[\"spoof\", \"live\"], zero_division=0))\n",
        "\n",
        "        # TensorBoard logs\n",
        "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
        "        writer.add_scalar('Acc/train', train_acc, epoch)\n",
        "        writer.add_scalar('Acc/val', val_acc, epoch)\n",
        "        writer.add_scalar('F1/macro_val', report['macro avg']['f1-score'], epoch)\n",
        "\n",
        "        # Early stopping + mejor modelo\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            trigger_times = 0\n",
        "            best_model_path = os.path.join(RUN_DIR, \"best_model.pth\")\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f'✅ Best model saved to {best_model_path}')\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            print(f'Early stopping trigger: {trigger_times}/{patience}')\n",
        "            if trigger_times >= patience:\n",
        "                print(\"⛔ Early stopping!\")\n",
        "                break\n",
        "\n",
        "        # Checkpoint por época\n",
        "        if (epoch + 1) % checkpoint_interval == 0:\n",
        "            checkpoint_path = os.path.join(RUN_DIR, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'train_acc': train_acc.item(),\n",
        "                'val_loss': val_loss,\n",
        "                'val_acc': val_acc.item(),\n",
        "            }, checkpoint_path)\n",
        "            print(f'📦 Checkpoint saved to {checkpoint_path}')\n",
        "\n",
        "    writer.close()\n",
        "    return model, train_loss, train_acc, val_loss, val_acc, report\n",
        "\n"
      ],
      "metadata": {
        "id": "62VUKKYL6vcy"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><strong>📚 Explicación detallada de funciones de entrenamiento</strong></summary>\n",
        "\n",
        "### 🔁 `train_epoch(...)`\n",
        "Esta función entrena el modelo durante una sola época usando *Mixed Precision Training* para mejorar el rendimiento y reducir el consumo de memoria en GPU.\n",
        "\n",
        "**Parámetros:**\n",
        "- `model`: modelo de red neuronal.\n",
        "- `train_loader`: `DataLoader` con los datos de entrenamiento.\n",
        "- `optimizer`: optimizador (por ejemplo, Adam).\n",
        "- `criterion`: función de pérdida.\n",
        "- `device`: CPU o GPU.\n",
        "- `scaler`: `GradScaler` para entrenamiento en precisión mixta.\n",
        "\n",
        "**Qué hace:**\n",
        "- Activa el modo entrenamiento del modelo.\n",
        "- Para cada batch:\n",
        "  - Ejecuta forward pass (predicción).\n",
        "  - Calcula la pérdida.\n",
        "  - Ejecuta backward pass y actualiza pesos (gradientes escalados).\n",
        "  - Acumula métricas: pérdida total y aciertos.\n",
        "\n",
        "**Devuelve:**\n",
        "- `epoch_loss`: pérdida media de la época.\n",
        "- `epoch_acc`: exactitud (accuracy) de entrenamiento.\n",
        "\n",
        "---\n",
        "\n",
        "### 📊 `validate_epoch(...)`\n",
        "Evalúa el modelo en el conjunto de validación y calcula métricas detalladas.\n",
        "\n",
        "**Parámetros:**\n",
        "- `model`: modelo entrenado.\n",
        "- `val_loader`: datos de validación.\n",
        "- `criterion`: función de pérdida.\n",
        "- `device`: CPU o GPU.\n",
        "\n",
        "**Qué hace:**\n",
        "- Activa el modo evaluación del modelo.\n",
        "- Desactiva cálculo de gradientes.\n",
        "- Calcula pérdida, predicciones y métricas en todo el conjunto.\n",
        "- Genera un `classification_report` con precisión, recall y F1.\n",
        "\n",
        "**Devuelve:**\n",
        "- `epoch_loss`: pérdida media.\n",
        "- `epoch_acc`: exactitud (accuracy).\n",
        "- `report`: diccionario con métricas detalladas (`f1-score`, `precision`, etc.).\n",
        "- `all_preds`: predicciones crudas.\n",
        "- `all_labels`: etiquetas verdaderas.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 `train_model(...)`\n",
        "Función principal de entrenamiento que combina las anteriores. Agrega:\n",
        "- Registro en TensorBoard.\n",
        "- Early Stopping.\n",
        "- Guardado de checkpoints y del mejor modelo.\n",
        "\n",
        "**Parámetros:**\n",
        "- `model`: red neuronal.\n",
        "- `train_loader`, `val_loader`: `DataLoader`s para entrenamiento y validación.\n",
        "- `criterion`: función de pérdida.\n",
        "- `optimizer`: algoritmo de optimización.\n",
        "- `device`: CPU o GPU.\n",
        "- `num_epochs`: total de épocas.\n",
        "- `patience`: épocas sin mejora antes de detener.\n",
        "- `checkpoint_interval`: cada cuántas épocas guardar.\n",
        "- `log_dir`: carpeta de logs de TensorBoard.\n",
        "\n",
        "**Qué hace:**\n",
        "- Itera por época:\n",
        "  - Entrena una época (`train_epoch`)\n",
        "  - Valida la época (`validate_epoch`)\n",
        "  - Registra métricas en TensorBoard\n",
        "  - Guarda el mejor modelo\n",
        "  - Aplica Early Stopping si no mejora\n",
        "  - Guarda checkpoints periódicos\n",
        "\n",
        "**Devuelve:**\n",
        "- El modelo final entrenado.\n",
        "\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "yIRhXM-i70N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# continua del bloque anterior, pero lo pongo aca para tenerlo separado\n",
        "# 🧪 Ejecución del entrenamiento (se asume que todo está definido)\n",
        "trained_model, train_loss, train_acc, val_loss, val_acc, val_report = train_model(\n",
        "    model, train_loader, val_loader,\n",
        "    criterion, optimizer, device,\n",
        "    num_epochs=10, patience=3\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NjeBDJpTUQQ",
        "outputId": "f59b20b7-a4f5-4bf5-c918-c80c9b19d77e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-70-2456198354.py:95: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-70-2456198354.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-70-2456198354.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔁 Learning Rate actual: 0.000500\n",
            "Train Loss: 0.0388  Acc: 0.9856\n",
            "Val Loss:   0.0673  Acc: 0.9756\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       1.00      0.96      0.98      6507\n",
            "        live       0.94      1.00      0.97      3493\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.97      0.98      0.97     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "✅ Best model saved to /content/drive/MyDrive/Tesis UTDT/experimentos/20250622-221825/best_model.pth\n",
            "📦 Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/experimentos/20250622-221825/checkpoint_epoch_1.pth\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-70-2456198354.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-70-2456198354.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔁 Learning Rate actual: 0.000500\n",
            "Train Loss: 0.0140  Acc: 0.9952\n",
            "Val Loss:   0.0723  Acc: 0.9760\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       1.00      0.96      0.98      6507\n",
            "        live       0.94      1.00      0.97      3493\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.97      0.98      0.97     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "Early stopping trigger: 1/3\n",
            "📦 Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/experimentos/20250622-221825/checkpoint_epoch_2.pth\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-70-2456198354.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-70-2456198354.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔁 Learning Rate actual: 0.000250\n",
            "Train Loss: 0.0122  Acc: 0.9957\n",
            "Val Loss:   0.0695  Acc: 0.9761\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       1.00      0.96      0.98      6507\n",
            "        live       0.94      1.00      0.97      3493\n",
            "\n",
            "    accuracy                           0.98     10000\n",
            "   macro avg       0.97      0.98      0.97     10000\n",
            "weighted avg       0.98      0.98      0.98     10000\n",
            "\n",
            "Early stopping trigger: 2/3\n",
            "📦 Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/experimentos/20250622-221825/checkpoint_epoch_3.pth\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-70-2456198354.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/tmp/ipython-input-70-2456198354.py:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔁 Learning Rate actual: 0.000250\n",
            "Train Loss: 0.0058  Acc: 0.9983\n",
            "Val Loss:   0.0805  Acc: 0.9734\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       1.00      0.96      0.98      6507\n",
            "        live       0.93      1.00      0.96      3493\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.96      0.98      0.97     10000\n",
            "weighted avg       0.98      0.97      0.97     10000\n",
            "\n",
            "Early stopping trigger: 3/3\n",
            "⛔ Early stopping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# 🧠 Cargar el mejor modelo desde el directorio de la corrida actual\n",
        "best_model = models.mobilenet_v2(pretrained=False)\n",
        "num_ftrs = best_model.classifier[1].in_features\n",
        "best_model.classifier[1] = nn.Linear(num_ftrs, 2)\n",
        "best_model.load_state_dict(torch.load(os.path.join(RUN_DIR, 'best_model.pth')))\n",
        "best_model = best_model.to(device)\n",
        "print(\"✅ Mejor modelo cargado desde RUN_DIR\")\n",
        "\n",
        "\n",
        "\n",
        "def test_model(model, test_loader, criterion, device, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    test_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Usar autocast para precisión mixta en la inferencia\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            total_samples += inputs.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = test_loss / total_samples\n",
        "    print(f'Test Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Convertir a arrays de numpy\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Calcular matriz de confusión y reporte en formato dict\n",
        "    cm = metrics.confusion_matrix(all_labels, all_preds)\n",
        "    report = metrics.classification_report(all_labels, all_preds, target_names=[\"spoof\", \"live\"], zero_division=0)\n",
        "    report_dict = metrics.classification_report(all_labels, all_preds, target_names=[\"spoof\", \"live\"], output_dict=True, zero_division=0)\n",
        "\n",
        "    # Guardar métricas como JSON\n",
        "    with open(os.path.join(output_dir, 'classification_report.json'), 'w') as f:\n",
        "        json.dump(report, f, indent=4)\n",
        "    print(\"📄 Reporte de clasificación guardado en JSON.\")\n",
        "\n",
        "    print(\"Matriz de Confusión:\")\n",
        "    print(cm)\n",
        "    print(\"Reporte de Clasificación:\")\n",
        "    print(report)\n",
        "\n",
        "    # Guardar matriz de confusión como imagen PNG\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"spoof\", \"live\"], yticklabels=[\"spoof\", \"live\"])\n",
        "    plt.xlabel(\"Predicción\")\n",
        "    plt.ylabel(\"Real\")\n",
        "    plt.title(\"Matriz de Confusión\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
        "    plt.close()\n",
        "    print(\"🖼️ Matriz de confusión guardada como imagen.\")\n",
        "\n",
        "    return avg_loss, report_dict, cm\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH9KuuHz72Uf",
        "outputId": "20b5c3b2-d454-4f00-ced0-14e7088666c7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Mejor modelo cargado desde RUN_DIR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><strong>🧪 Evaluación del modelo sobre el conjunto de test</strong></summary>\n",
        "\n",
        "Esta etapa evalúa el modelo entrenado sobre un conjunto independiente de prueba. La función `test_model` se encarga de calcular:\n",
        "\n",
        "- La pérdida promedio (`test_loss`)\n",
        "- Métricas de clasificación como:\n",
        "  - Accuracy\n",
        "  - Precision\n",
        "  - Recall\n",
        "  - F1-score (por clase y macro)\n",
        "- La matriz de confusión\n",
        "- Una visualización gráfica con `seaborn`\n",
        "\n",
        "### 🔍 Detalles técnicos:\n",
        "- El modelo se evalúa en modo `eval()` y sin cálculo de gradientes (`no_grad()`).\n",
        "- Se usa `autocast()` para inferencia eficiente con precisión mixta (float16).\n",
        "- Las predicciones y etiquetas se acumulan para calcular métricas globales con `sklearn.metrics`.\n",
        "\n",
        "### 📊 Resultado esperado:\n",
        "- Impresión por consola del `classification_report`.\n",
        "- Visualización clara de errores y aciertos con una matriz de confusión coloreada.\n",
        "- Retorno de:\n",
        "  - `avg_loss`: pérdida total dividida por cantidad de muestras.\n",
        "  - `report`: diccionario con todas las métricas.\n",
        "  - `cm`: matriz de confusión en formato NumPy.\n",
        "\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "npG9kS0k8tDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Continuacion del bloque anterior. Testeo del modelo en otro dataset\n",
        "test_data_dir2 = '/content/drive/Othercomputers/My Mac/Data/test'\n",
        "\n",
        "test_dataset2 = CelebASpoofDataset(\n",
        "    root_dir=test_data_dir2,\n",
        "    transform=data_transforms['test'],\n",
        "    cache_file=os.path.join(CACHE_DIR, 'test_dataset_cache_full.pkl'),\n",
        "    max_samples=10000\n",
        "    # max_subjects=300\n",
        ")\n",
        "\n",
        "\n",
        "# DataLoaders\n",
        "test_loader2 = DataLoader(test_dataset2, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# test_loss, test_report, test_cm = test_model(model, test_loader2, criterion, device)\n",
        "test_loss, test_report, test_cm = test_model(best_model, test_loader2, criterion, device, output_dir=RUN_DIR)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGz2agcmUXdn",
        "outputId": "ec6e10ba-be7a-46a4-ddf7-07551abe12dd"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando dataset desde cache...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-72-328312363.py:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.5762\n",
            "📄 Reporte de clasificación guardado en JSON.\n",
            "Matriz de Confusión:\n",
            "[[1353 3972]\n",
            " [   7 4668]]\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       0.99      0.25      0.40      5325\n",
            "        live       0.54      1.00      0.70      4675\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.77      0.63      0.55     10000\n",
            "weighted avg       0.78      0.60      0.54     10000\n",
            "\n",
            "🖼️ Matriz de confusión guardada como imagen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def log_experiment_summary(run_dir,\n",
        "                           train_loss, train_acc,\n",
        "                           val_loss, val_acc, val_report,\n",
        "                           test_loss, test_report,\n",
        "                           train_max_samples, val_max_samples, test_max_samples):\n",
        "    summary_path = os.path.join(EXPERIMENTS_DIR, \"all_runs.csv\")\n",
        "    run_name = os.path.basename(run_dir)\n",
        "\n",
        "    # Utilidad segura para extraer métricas, aunque una clase no esté presente\n",
        "    def get_metric(report, class_name, metric):\n",
        "        return round(report.get(class_name, {}).get(metric, 0.0), 4)\n",
        "\n",
        "    summary_data = {\n",
        "        \"run_name\": run_name,\n",
        "\n",
        "        # Métricas de entrenamiento\n",
        "        \"train_loss\": round(train_loss, 4),\n",
        "        \"train_acc\": round(train_acc.item(), 4),\n",
        "\n",
        "        # Métricas de validación\n",
        "        \"val_loss\": round(val_loss, 4),\n",
        "        \"val_acc\": round(val_acc.item(), 4),\n",
        "        \"f1_macro_val\": get_metric(val_report, \"macro avg\", \"f1-score\"),\n",
        "        \"precision_spoof_val\": get_metric(val_report, \"0\", \"precision\"),\n",
        "        \"recall_spoof_val\": get_metric(val_report, \"0\", \"recall\"),\n",
        "        \"f1_spoof_val\": get_metric(val_report, \"0\", \"f1-score\"),\n",
        "        \"precision_live_val\": get_metric(val_report, \"1\", \"precision\"),\n",
        "        \"recall_live_val\": get_metric(val_report, \"1\", \"recall\"),\n",
        "        \"f1_live_val\": get_metric(val_report, \"1\", \"f1-score\"),\n",
        "\n",
        "        # Métricas de test final\n",
        "        \"test_loss\": round(test_loss, 4),\n",
        "        \"f1_macro_test\": get_metric(test_report, \"macro avg\", \"f1-score\"),\n",
        "        \"precision_spoof_test\": get_metric(test_report, \"spoof\", \"precision\"),\n",
        "        \"recall_spoof_test\": get_metric(test_report, \"spoof\", \"recall\"),\n",
        "        \"f1_spoof_test\": get_metric(test_report, \"spoof\", \"f1-score\"),\n",
        "        \"precision_live_test\": get_metric(test_report, \"live\", \"precision\"),\n",
        "        \"recall_live_test\": get_metric(test_report, \"live\", \"recall\"),\n",
        "        \"f1_live_test\": get_metric(test_report, \"live\", \"f1-score\"),\n",
        "\n",
        "        # Info de dataset\n",
        "        \"train_max_samples\": train_max_samples,\n",
        "        \"val_max_samples\": val_max_samples,\n",
        "        \"test_max_samples\": test_max_samples\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame([summary_data])\n",
        "    if os.path.exists(summary_path):\n",
        "        df.to_csv(summary_path, mode='a', header=False, index=False)\n",
        "    else:\n",
        "        df.to_csv(summary_path, index=False)\n",
        "\n",
        "    print(f\"📝 Resumen de la corrida guardado en {summary_path}\")\n"
      ],
      "metadata": {
        "id": "XW8B2HBXX5-M"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAsTob5fZ_iW",
        "outputId": "e1d17fe2-14c8-438d-94b4-9067758f7a2e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spoof': {'precision': 0.9948529411764706,\n",
              "  'recall': 0.2540845070422535,\n",
              "  'f1-score': 0.40478683620044875,\n",
              "  'support': 5325.0},\n",
              " 'live': {'precision': 0.5402777777777777,\n",
              "  'recall': 0.9985026737967915,\n",
              "  'f1-score': 0.7011641006383778,\n",
              "  'support': 4675.0},\n",
              " 'accuracy': 0.6021,\n",
              " 'macro avg': {'precision': 0.7675653594771241,\n",
              "  'recall': 0.6262935904195225,\n",
              "  'f1-score': 0.5529754684194133,\n",
              "  'support': 10000.0},\n",
              " 'weighted avg': {'precision': 0.7823390522875817,\n",
              "  'recall': 0.6021,\n",
              "  'f1-score': 0.5433432073251805,\n",
              "  'support': 10000.0}}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_experiment_summary(\n",
        "    run_dir=RUN_DIR,\n",
        "    train_loss=train_loss,\n",
        "    train_acc=train_acc,\n",
        "    val_loss=val_loss,\n",
        "    val_acc=val_acc,\n",
        "    val_report=val_report,\n",
        "    test_loss=test_loss,\n",
        "    test_report=test_report,\n",
        "    train_max_samples=train_max_samples,\n",
        "    val_max_samples=val_max_samples,\n",
        "    test_max_samples=test_max_samples\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE0EMB-aYERA",
        "outputId": "6743577a-a937-4e30-fc21-424153291e02"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📝 Resumen de la corrida guardado en /content/drive/MyDrive/Tesis UTDT/experimentos/all_runs.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar 10 predicciones incorrectas con su path\n",
        "for i, (img, label) in enumerate(test_dataset):\n",
        "    pred = model(img.unsqueeze(0).to(device)).argmax(dim=1).item()\n",
        "    if pred != label:\n",
        "        print(f\"ERROR → Pred: {pred} | Real: {label} | Path: {test_dataset.image_paths[i]}\")\n",
        "        if i > 10: break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBXaRogcnMSE",
        "outputId": "a50fbf53-54eb-4796-8513-78caa796ae6f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR → Pred: 1 | Real: 0 | Path: /content/drive/Othercomputers/My Mac/Data/train/test/9893/spoof/192739.jpg\n",
            "ERROR → Pred: 1 | Real: 0 | Path: /content/drive/Othercomputers/My Mac/Data/train/test/9893/spoof/179815.jpg\n"
          ]
        }
      ]
    }
  ]
}