{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrorostagno/tesis/blob/main/Tesis_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xePy61K1FUjq",
        "outputId": "4d5c49e9-a3eb-4078-9482-9a64a4fb8bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdAdU6l7GIFI"
      },
      "outputs": [],
      "source": [
        "dataset_path = '/content/drive/Othercomputers/My Mac/Data/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEaET5xZP4Q4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbIix4cXU6cG"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CelebASpoofDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, cache_file=None, max_samples=None):\n",
        "        \"\"\"\n",
        "        root_dir: Ruta raíz del dataset.\n",
        "        transform: Transformaciones a aplicar a cada imagen.\n",
        "        cache_file: Ruta al archivo de cache (opcional).\n",
        "        max_samples: Número máximo de muestras a cargar (opcional).\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        if cache_file is not None and os.path.exists(cache_file):\n",
        "            print(\"Cargando dataset desde cache...\")\n",
        "            with open(cache_file, 'rb') as f:\n",
        "                self.image_paths, self.labels = pickle.load(f)\n",
        "        else:\n",
        "            print(\"Generando la lista de imágenes usando os.scandir...\")\n",
        "            # Variable para determinar si ya se alcanzó el máximo de muestras\n",
        "            max_reached = False\n",
        "            with os.scandir(root_dir) as subjects:\n",
        "                for subject in subjects:\n",
        "                    if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "                        max_reached = True\n",
        "                        break\n",
        "                    if subject.is_dir():\n",
        "                        subject_path = subject.path\n",
        "                        with os.scandir(subject_path) as type_entries:\n",
        "                            for entry in type_entries:\n",
        "                                if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "                                    max_reached = True\n",
        "                                    break\n",
        "                                if entry.is_dir():\n",
        "                                    image_type = entry.name  # 'live' o 'spoof'\n",
        "                                    with os.scandir(entry.path) as files:\n",
        "                                        for file_entry in files:\n",
        "                                            if file_entry.is_file() and file_entry.name.lower().endswith(('.jpg', '.png')):\n",
        "                                                self.image_paths.append(file_entry.path)\n",
        "                                                self.labels.append(0 if image_type == 'spoof' else 1)\n",
        "                                                if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "                                                    max_reached = True\n",
        "                                                    break\n",
        "                                        if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "                                            break\n",
        "                            if max_samples is not None and len(self.image_paths) >= max_samples:\n",
        "                                break\n",
        "                    if max_reached:\n",
        "                        break\n",
        "            # Guardar en cache si se especifica\n",
        "            if cache_file is not None:\n",
        "                with open(cache_file, 'wb') as f:\n",
        "                    pickle.dump((self.image_paths, self.labels), f)\n",
        "                print(\"Cache guardado en\", cache_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNnqs83EToA5"
      },
      "outputs": [],
      "source": [
        "# Paths to each split\n",
        "train_data_dir = '/content/drive/Othercomputers/My Mac/Data/train/train'\n",
        "val_data_dir = '/content/drive/Othercomputers/My Mac/Data/train/val'\n",
        "test_data_dir = '/content/drive/Othercomputers/My Mac/Data/train/test'\n",
        "\n",
        "img_width, img_height = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((img_width, img_height)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((img_width, img_height)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((img_width, img_height)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWLu2YKT1ky6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c3d95a-1d5a-47c4-d633-4fe95ec2a3e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando dataset desde cache...\n",
            "Cargando dataset desde cache...\n",
            "Generando la lista de imágenes usando os.scandir...\n",
            "Cache guardado en /content/drive/MyDrive/Tesis UTDT/test_dataset_cache.pkl\n"
          ]
        }
      ],
      "source": [
        "# Datasets con max_samples\n",
        "train_dataset = CelebASpoofDataset(\n",
        "    root_dir=train_data_dir,\n",
        "    transform=data_transforms['train'],\n",
        "    cache_file='/content/drive/MyDrive/Tesis UTDT/train_dataset_cache.pkl',\n",
        "    max_samples=5000\n",
        ")\n",
        "val_dataset = CelebASpoofDataset(\n",
        "    root_dir=val_data_dir,\n",
        "    transform=data_transforms['val'],\n",
        "    cache_file='/content/drive/MyDrive/Tesis UTDT/val_dataset_cache.pkl',\n",
        "    max_samples=1000\n",
        ")\n",
        "test_dataset = CelebASpoofDataset(\n",
        "    root_dir=test_data_dir,\n",
        "    transform=data_transforms['test'],\n",
        "    cache_file='/content/drive/MyDrive/Tesis UTDT/test_dataset_cache.pkl',\n",
        "    max_samples=1000\n",
        ")\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbloOM1mVavx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef6536b-e2be-40c0-95cc-4fe1490d3511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 210MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.mobilenet_v2(pretrained=True)\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, 2)  # 2 classes: real and fake\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65R-GiOCVhld"
      },
      "outputs": [],
      "source": [
        "# Device (GPU or CPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular la distribución de clases a partir del dataset de entrenamiento\n",
        "labels = np.array(train_dataset.labels)\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "print(f\"Distribución de clases en entrenamiento: {dict(zip(unique, counts))}\")\n",
        "\n",
        "total = counts.sum()\n",
        "# Pesos inversos: mayor peso para la clase menos representada\n",
        "weights = [total / c for c in counts]\n",
        "weights_tensor = torch.FloatTensor(weights).to(device)\n",
        "print(\"Pesos de clases:\", weights_tensor)\n",
        "\n",
        "# Definir la función de pérdida ponderada\n",
        "criterion = nn.CrossEntropyLoss(weight=weights_tensor)\n",
        "\n",
        "# El resto de tu código (modelo, optimizador, bucle de entrenamiento) sigue igual.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-sj1DyKezfH",
        "outputId": "0ef7669b-fa27-4f4d-e6c6-74441069be73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución de clases en entrenamiento: {0: 3222, 1: 1778}\n",
            "Pesos de clases: tensor([1.5518, 2.8121], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1h-PozJVmKQ",
        "outputId": "99fbc934-9c2f-41ea-92a4-1542f08ec835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.0448 - Acc: 0.9688\n",
            "Train Loss: 0.0829 Acc: 0.9700\n",
            "Val Loss: 0.2979 Acc: 0.8780\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_1.pth\n",
            "Epoch 2/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.0153 - Acc: 1.0000\n",
            "Train Loss: 0.0412 Acc: 0.9866\n",
            "Val Loss: 0.1330 Acc: 0.9320\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_2.pth\n",
            "Epoch 3/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.1039 - Acc: 0.9688\n",
            "Train Loss: 0.0299 Acc: 0.9892\n",
            "Val Loss: 0.2624 Acc: 0.9250\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_3.pth\n",
            "Epoch 4/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.0250 - Acc: 0.9688\n",
            "Train Loss: 0.0352 Acc: 0.9882\n",
            "Val Loss: 0.1476 Acc: 0.9750\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_4.pth\n",
            "Epoch 5/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.1123 - Acc: 0.9375\n",
            "Train Loss: 0.0245 Acc: 0.9918\n",
            "Val Loss: 0.2124 Acc: 0.9200\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_5.pth\n",
            "Epoch 6/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.0001 - Acc: 1.0000\n",
            "Train Loss: 0.0176 Acc: 0.9944\n",
            "Val Loss: 0.1443 Acc: 0.9410\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_6.pth\n",
            "Epoch 7/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.0001 - Acc: 1.0000\n",
            "Train Loss: 0.0325 Acc: 0.9912\n",
            "Val Loss: 0.1413 Acc: 0.9330\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_7.pth\n",
            "Epoch 8/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.0063 - Acc: 1.0000\n",
            "Train Loss: 0.0140 Acc: 0.9958\n",
            "Val Loss: 0.0386 Acc: 0.9770\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_8.pth\n",
            "Epoch 9/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.0000 - Acc: 1.0000\n",
            "Train Loss: 0.0079 Acc: 0.9964\n",
            "Val Loss: 0.1857 Acc: 0.9400\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_9.pth\n",
            "Epoch 10/10\n",
            "----------\n",
            "Batch 100/157 - Loss: 0.0061 - Acc: 1.0000\n",
            "Train Loss: 0.0100 Acc: 0.9966\n",
            "Val Loss: 0.1218 Acc: 0.9460\n",
            "Checkpoint saved to /content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_10.pth\n",
            "Finished Training\n",
            "Final model saved as real_fake_detection_model.pth\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "checkpoint_interval = 1\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        total_samples += inputs.size(0)\n",
        "        # Print progress every 100 batches\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "          print(f'Batch {i + 1}/{len(train_loader)} - Loss: {loss.item():.4f} - Acc: {(torch.sum(preds == labels.data) / inputs.size(0)):.4f}')\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = running_corrects.double() / total_samples\n",
        "    print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_corrects = 0\n",
        "    val_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "            val_samples += inputs.size(0)\n",
        "\n",
        "    val_epoch_loss = val_loss / val_samples\n",
        "    val_epoch_acc = val_corrects.double() / val_samples\n",
        "    print(f'Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f}')\n",
        "\n",
        "    # Save checkpoint\n",
        "    if (epoch + 1) % checkpoint_interval == 0:\n",
        "        checkpoint_path = f'/content/drive/MyDrive/Tesis UTDT/checkpoint_epoch_{epoch + 1}.pth'\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': epoch_loss,\n",
        "            'train_acc': epoch_acc.item(),\n",
        "            'val_loss': val_epoch_loss,\n",
        "            'val_acc': val_epoch_acc.item(),\n",
        "        }, checkpoint_path)\n",
        "        print(f'Checkpoint saved to {checkpoint_path}')\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Save the trained model\n",
        "final_model_path = '/content/drive/MyDrive/Tesis UTDT/real_fake_detection_model.pth'\n",
        "torch.save(model.state_dict(), final_model_path)\n",
        "print('Final model saved as real_fake_detection_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "import time\n",
        "\n",
        "# Función para entrenar una época (Mixed Precision Training)\n",
        "def train_epoch(model, train_loader, optimizer, criterion, device, scaler):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        total_samples += inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = running_corrects.double() / total_samples\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Función para validar una época y calcular métricas adicionales\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_corrects = 0\n",
        "    total_samples = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            with autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = val_loss / total_samples\n",
        "    epoch_acc = val_corrects.double() / total_samples\n",
        "    # Reporte de métricas adicionales (por ejemplo, F1-score macro)\n",
        "    report = metrics.classification_report(all_labels, all_preds, output_dict=True, zero_division=0)\n",
        "\n",
        "    return epoch_loss, epoch_acc, report, all_preds, all_labels\n",
        "\n",
        "# Función principal de entrenamiento que integra early stopping y TensorBoard\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10, patience=3, checkpoint_interval=1, log_dir='logs/exp1'):\n",
        "    writer = SummaryWriter(log_dir=log_dir)\n",
        "    scaler = GradScaler()\n",
        "    best_val_loss = float('inf')\n",
        "    trigger_times = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Entrenamiento\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device, scaler)\n",
        "        print(f'Train Loss: {train_loss:.4f}  Acc: {train_acc:.4f}')\n",
        "\n",
        "        # Validación\n",
        "        val_loss, val_acc, report, all_preds, all_labels = validate_epoch(model, val_loader, criterion, device)\n",
        "        print(f'Val Loss: {val_loss:.4f}  Acc: {val_acc:.4f}')\n",
        "        print(metrics.classification_report(all_labels, all_preds, target_names=[\"spoof\", \"live\"], zero_division=0))\n",
        "\n",
        "        # Registro de métricas en TensorBoard\n",
        "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
        "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
        "        writer.add_scalar('Acc/train', train_acc, epoch)\n",
        "        writer.add_scalar('Acc/val', val_acc, epoch)\n",
        "        macro_f1 = report['macro avg']['f1-score']\n",
        "        writer.add_scalar('F1/macro_val', macro_f1, epoch)\n",
        "\n",
        "        # Early Stopping: Si la pérdida de validación mejora, se guarda el mejor modelo.\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            trigger_times = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "            print('Best model saved')\n",
        "        else:\n",
        "            trigger_times += 1\n",
        "            print(f'Early stopping trigger: {trigger_times}/{patience}')\n",
        "            if trigger_times >= patience:\n",
        "                print(\"Early stopping!\")\n",
        "                break\n",
        "\n",
        "        # Guardar checkpoint cada checkpoint_interval épocas\n",
        "        if (epoch+1) % checkpoint_interval == 0:\n",
        "            checkpoint_path = f'checkpoint_epoch_{epoch+1}.pth'\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'train_acc': train_acc.item(),\n",
        "                'val_loss': val_loss,\n",
        "                'val_acc': val_acc.item(),\n",
        "            }, checkpoint_path)\n",
        "            print(f'Checkpoint saved to {checkpoint_path}')\n",
        "\n",
        "    writer.close()\n",
        "    return model\n",
        "\n",
        "# Ejemplo de uso:\n",
        "# Asumiendo que ya tienes definido:\n",
        "# - model (por ejemplo, MobileNetV2 modificado)\n",
        "# - train_loader, val_loader (DataLoaders)\n",
        "# - criterion (por ejemplo, nn.CrossEntropyLoss con o sin pesos)\n",
        "# - optimizer (por ejemplo, optim.Adam(model.parameters(), lr=0.001))\n",
        "# - device (por ejemplo, torch.device(\"cuda:0\") si hay GPU)\n",
        "#\n",
        "# Luego, para entrenar:\n",
        "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10, patience=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PWt0pQ22rez",
        "outputId": "e1a87572-0fb9-4b63-de68-f09f71c96d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:76: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "<ipython-input-17-ae200ec3e4dd>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0154  Acc: 0.9942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1899  Acc: 0.9140\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       0.99      0.87      0.93       634\n",
            "        live       0.82      0.99      0.89       366\n",
            "\n",
            "    accuracy                           0.91      1000\n",
            "   macro avg       0.90      0.93      0.91      1000\n",
            "weighted avg       0.93      0.91      0.92      1000\n",
            "\n",
            "Best model saved\n",
            "Checkpoint saved to checkpoint_epoch_1.pth\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0088  Acc: 0.9970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0756  Acc: 0.9660\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       1.00      0.95      0.97       634\n",
            "        live       0.92      1.00      0.96       366\n",
            "\n",
            "    accuracy                           0.97      1000\n",
            "   macro avg       0.96      0.97      0.96      1000\n",
            "weighted avg       0.97      0.97      0.97      1000\n",
            "\n",
            "Best model saved\n",
            "Checkpoint saved to checkpoint_epoch_2.pth\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0047  Acc: 0.9984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0808  Acc: 0.9650\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       1.00      0.95      0.97       634\n",
            "        live       0.92      0.99      0.95       366\n",
            "\n",
            "    accuracy                           0.96      1000\n",
            "   macro avg       0.96      0.97      0.96      1000\n",
            "weighted avg       0.97      0.96      0.97      1000\n",
            "\n",
            "Early stopping trigger: 1/3\n",
            "Checkpoint saved to checkpoint_epoch_3.pth\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0158  Acc: 0.9940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0391  Acc: 0.9900\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       0.99      1.00      0.99       634\n",
            "        live       0.99      0.98      0.99       366\n",
            "\n",
            "    accuracy                           0.99      1000\n",
            "   macro avg       0.99      0.99      0.99      1000\n",
            "weighted avg       0.99      0.99      0.99      1000\n",
            "\n",
            "Best model saved\n",
            "Checkpoint saved to checkpoint_epoch_4.pth\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0294  Acc: 0.9888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0473  Acc: 0.9880\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       0.98      1.00      0.99       634\n",
            "        live       0.99      0.97      0.98       366\n",
            "\n",
            "    accuracy                           0.99      1000\n",
            "   macro avg       0.99      0.98      0.99      1000\n",
            "weighted avg       0.99      0.99      0.99      1000\n",
            "\n",
            "Early stopping trigger: 1/3\n",
            "Checkpoint saved to checkpoint_epoch_5.pth\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0296  Acc: 0.9922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0927  Acc: 0.9620\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       0.99      0.95      0.97       634\n",
            "        live       0.91      0.99      0.95       366\n",
            "\n",
            "    accuracy                           0.96      1000\n",
            "   macro avg       0.95      0.97      0.96      1000\n",
            "weighted avg       0.96      0.96      0.96      1000\n",
            "\n",
            "Early stopping trigger: 2/3\n",
            "Checkpoint saved to checkpoint_epoch_6.pth\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0148  Acc: 0.9954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-ae200ec3e4dd>:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.0399  Acc: 0.9830\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       1.00      0.98      0.99       634\n",
            "        live       0.96      0.99      0.98       366\n",
            "\n",
            "    accuracy                           0.98      1000\n",
            "   macro avg       0.98      0.98      0.98      1000\n",
            "weighted avg       0.98      0.98      0.98      1000\n",
            "\n",
            "Early stopping trigger: 3/3\n",
            "Early stopping!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def test_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    test_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Usar autocast para precisión mixta en la inferencia\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            test_loss += loss.item() * inputs.size(0)\n",
        "            total_samples += inputs.size(0)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = test_loss / total_samples\n",
        "    print(f'Test Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Convertir a arrays de numpy\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Calcular la matriz de confusión y el reporte de clasificación\n",
        "    cm = metrics.confusion_matrix(all_labels, all_preds)\n",
        "    report = metrics.classification_report(all_labels, all_preds, target_names=[\"spoof\", \"live\"], zero_division=0)\n",
        "\n",
        "    print(\"Matriz de Confusión:\")\n",
        "    print(cm)\n",
        "    print(\"Reporte de Clasificación:\")\n",
        "    print(report)\n",
        "\n",
        "    # Visualizar la matriz de confusión\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=[\"spoof\", \"live\"],\n",
        "                yticklabels=[\"spoof\", \"live\"])\n",
        "    plt.xlabel(\"Predicción\")\n",
        "    plt.ylabel(\"Real\")\n",
        "    plt.title(\"Matriz de Confusión\")\n",
        "    plt.show()\n",
        "\n",
        "    return avg_loss, report, cm\n",
        "\n",
        "test_data_dir2 = '/content/drive/Othercomputers/My Mac/Data/test'\n",
        "\n",
        "test_dataset2 = CelebASpoofDataset(\n",
        "    root_dir=test_data_dir2,\n",
        "    transform=data_transforms['test'],\n",
        "    cache_file='/content/drive/MyDrive/Tesis UTDT/test_dataset_cache2.pkl',\n",
        "    max_samples=10000\n",
        ")\n",
        "\n",
        "\n",
        "# DataLoaders\n",
        "test_loader2 = DataLoader(test_dataset2, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "\n",
        "# Ejemplo de uso:\n",
        "test_loss, test_report, test_cm = test_model(model, test_loader2, criterion, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "uqMFNPAW34cf",
        "outputId": "0686c439-d243-470e-ba09-81940f0f3f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando dataset desde cache...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-9a5e2b61b5c5>:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.2223\n",
            "Matriz de Confusión:\n",
            "[[2190 3135]\n",
            " [  32 4643]]\n",
            "Reporte de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       spoof       0.99      0.41      0.58      5325\n",
            "        live       0.60      0.99      0.75      4675\n",
            "\n",
            "    accuracy                           0.68     10000\n",
            "   macro avg       0.79      0.70      0.66     10000\n",
            "weighted avg       0.80      0.68      0.66     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U5OKbCKsyHDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "history_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1dNq1p8q_inhSmI0LD0IU5Z7jrx4uWikp",
      "authorship_tag": "ABX9TyPUfhAo8NcjW9NCDEbK2Hb0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}